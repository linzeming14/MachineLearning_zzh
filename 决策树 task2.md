### 决策树 ——《西瓜书》周志华

------

1.  基本流程

   决策树(decision tree) 是一类常见的机器学习方法。顾名思义， 决策树是基于树结构进行决策的。一般的， 一棵树包含一个根节点、 若干个内部结点、若干个叶节点。

   - 叶结点对应于决策结果， 其他每个节点则对应于每个属性测试.每个结点包含的样本集合根据属性测试的结果被划分到子结点钟；

   - 根结点包含样全集，从根结点到每个叶节点的路径对应了一个判定测试序列。

     决策树学习的目的是为了产生一棵泛化能力强的决策树，其基本流程遵循简单且直观的“分而治之（divide-and-conquer）”策略。

     ------

     **输入：**训练集$D={(x_1, y_1), (x_2, y_2), ..., (x_m, y_m)}$

     ​			属性集合$A={a_1, a_2, ..., a_d}$.

     **过程：**函数 $TreeGenerate(D,A)$

     1: 生成结点node

     2: **if** $D$中样本全属于同类别$C$ **then**

     3:		将node标记为$C$类叶结点; **return**

     4: **end if**

     5: **if **$A=\varnothing$ **OR**$D$中的样本在$A$上的取值相同 **then**
     6：        将node标记为叶结点， 其类别标记为$D$中样本数最多的类；**return**

     7：**end if**

     8： 从$A$中选取最优划分属性$a_*$;

     9: **for** $a_*$的每一个值$a_*^v$ **do**

     10：				为node生成一个分支；令$D_v$表示D中在$a_*$上的取值为$a_*^v$的样本子集；

     11：			**if** $D_v$为空 **then**

     12：						将分支结点标记为叶结点， 其类别标记为$D$中样本最多的类；**return**

     13：			**else**

     14：                 以 $TreeGenerate(D_v, A\\{a_*\})$为分支结点

     15: 			**endif**

     16: **end for**

     **输出：**以node为根结点的一棵决策树

     ------

     